{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nDsVMGiVgSq2"
   },
   "source": [
    "## Классификация FashionMNIST\n",
    "\n",
    "##### Автор: [Радослав Нейчев](https://www.linkedin.com/in/radoslav-neychev/), https://t.me/s/girafe_ai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "id": "3isBRG6PgSq6"
   },
   "outputs": [],
   "source": [
    "# do not change the code in the block below\n",
    "# __________start of block__________\n",
    "import json\n",
    "import os\n",
    "import re\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "import torchvision\n",
    "from IPython.display import clear_output\n",
    "from matplotlib import pyplot as plt\n",
    "from torch import nn\n",
    "from torch.nn import functional as F\n",
    "from torchvision.datasets import FashionMNIST\n",
    "\n",
    "# __________end of block__________"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# do not change the code in the block below\n",
    "# __________start of block__________\n",
    "def get_predictions(model, eval_data, step=10):\n",
    "\n",
    "    predicted_labels = []\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        for idx in range(0, len(eval_data), step):\n",
    "            y_predicted = model(eval_data[idx : idx + step].to(device))\n",
    "            predicted_labels.append(y_predicted.argmax(dim=1).cpu())\n",
    "\n",
    "    predicted_labels = torch.cat(predicted_labels)\n",
    "    predicted_labels = \",\".join([str(x.item()) for x in list(predicted_labels)])\n",
    "    return predicted_labels\n",
    "\n",
    "\n",
    "def get_accuracy(model, data_loader):\n",
    "    predicted_labels = []\n",
    "    real_labels = []\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        for batch in data_loader:\n",
    "            y_predicted = model(batch[0].to(device))\n",
    "            predicted_labels.append(y_predicted.argmax(dim=1).cpu())\n",
    "            real_labels.append(batch[1])\n",
    "\n",
    "    predicted_labels = torch.cat(predicted_labels)\n",
    "    real_labels = torch.cat(real_labels)\n",
    "    accuracy_score = (predicted_labels == real_labels).type(torch.FloatTensor).mean()\n",
    "    return accuracy_score\n",
    "\n",
    "\n",
    "# __________end of block__________"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Загрузите файл `hw_overfitting_data_dict.npy` (ссылка есть на странице с заданием), он понадобится для генерации посылок. Код ниже может его загрузить (но в случае возникновения ошибки скачайте и загрузите его вручную).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2025-04-10 22:36:06--  https://github.com/girafe-ai/ml-course/raw/24f_ysda/homeworks/hw_overfitting/hw_overfitting_data_dict\n",
      "Распознаётся github.com (github.com)… 140.82.121.4\n",
      "Подключение к github.com (github.com)|140.82.121.4|:443... соединение установлено.\n",
      "HTTP-запрос отправлен. Ожидание ответа… 302 Found\n",
      "Адрес: https://raw.githubusercontent.com/girafe-ai/ml-course/24f_ysda/homeworks/hw_overfitting/hw_overfitting_data_dict [переход]\n",
      "--2025-04-10 22:36:06--  https://raw.githubusercontent.com/girafe-ai/ml-course/24f_ysda/homeworks/hw_overfitting/hw_overfitting_data_dict\n",
      "Распознаётся raw.githubusercontent.com (raw.githubusercontent.com)… 185.199.109.133, 185.199.110.133, 185.199.108.133, ...\n",
      "Подключение к raw.githubusercontent.com (raw.githubusercontent.com)|185.199.109.133|:443... соединение установлено.\n",
      "HTTP-запрос отправлен. Ожидание ответа… 200 OK\n",
      "Длина: 6272446 (6,0M) [application/octet-stream]\n",
      "Сохранение в: ‘hw_overfitting_data_dict.npy’\n",
      "\n",
      "hw_overfitting_data 100%[===================>]   5,98M  7,67MB/s    за 0,8s    \n",
      "\n",
      "2025-04-10 22:36:08 (7,67 MB/s) - ‘hw_overfitting_data_dict.npy’ сохранён [6272446/6272446]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!wget https://github.com/girafe-ai/ml-course/raw/24f_ysda/homeworks/hw_overfitting/hw_overfitting_data_dict -O hw_overfitting_data_dict.npy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# do not change the code in the block below\n",
    "# __________start of block__________\n",
    "assert os.path.exists(\n",
    "    \"hw_overfitting_data_dict.npy\"\n",
    "), \"Please, download `hw_overfitting_data_dict.npy` and place it in the working directory\"\n",
    "\n",
    "# __________end of block__________"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zeA6Q5-CgSq7"
   },
   "source": [
    "Вернемся к задаче распознавания простых изображений, рассмотренной ранее. Но теперь будем работать с набором данных [FashionMNIST](https://github.com/zalandoresearch/fashion-mnist). В данном задании воспользуемся всем датасетом целиком.\n",
    "\n",
    "__Ваша первая задача: реализовать весь пайплан обучения модели и добиться качества $\\geq 88.5\\%$ на тестовой выборке.__\n",
    "\n",
    "Код для обучения модели в данном задании отсутствует. Присутствует лишь несколько тестов, которые помогут вам отладить свое решение. За примером можно обратиться к ноутбукам с предыдущих занятий."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "CUDA_DEVICE_ID = 0  # change if needed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "id": "nPG1KbQAgl8b"
   },
   "outputs": [],
   "source": [
    "# do not change the code in the block below\n",
    "# __________start of block__________\n",
    "device = (\n",
    "    torch.device(f\"cuda:{CUDA_DEVICE_ID}\") if torch.cuda.is_available() else torch.device(\"cpu\")\n",
    ")\n",
    "# __________end of block__________"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 809
    },
    "id": "aYcL28OsgSq8",
    "outputId": "93aafa07-fb56-43bd-f928-918f45fe30e6"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5, 1.0, 'Image label: 1')"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# do not change the code in the block below\n",
    "# __________start of block__________\n",
    "\n",
    "train_fmnist_data = FashionMNIST(\n",
    "    \".\", train=True, transform=torchvision.transforms.ToTensor(), download=True\n",
    ")\n",
    "test_fmnist_data = FashionMNIST(\n",
    "    \".\", train=False, transform=torchvision.transforms.ToTensor(), download=True\n",
    ")\n",
    "\n",
    "\n",
    "train_data_loader = torch.utils.data.DataLoader(\n",
    "    train_fmnist_data, batch_size=32, shuffle=True, num_workers=2\n",
    ")\n",
    "\n",
    "test_data_loader = torch.utils.data.DataLoader(\n",
    "    test_fmnist_data, batch_size=32, shuffle=False, num_workers=2\n",
    ")\n",
    "\n",
    "random_batch = next(iter(train_data_loader))\n",
    "_image, _label = random_batch[0][0], random_batch[1][0]\n",
    "plt.figure()\n",
    "plt.imshow(_image.reshape(28, 28))\n",
    "plt.title(f\"Image label: {_label}\")\n",
    "# __________end of block__________"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "S6jWRv1rgSq8"
   },
   "source": [
    "Постройте модель ниже. Пожалуйста, не стройте переусложненную сеть, не стоит делать ее глубже четырех слоев (можно и меньше). Ваша основная задача – обучить модель и получить качество на отложенной (тестовой выборке) не менее 88.5% accuracy.\n",
    "\n",
    "__Внимание, ваша модель должна быть представлена именно переменной `model_task_1`. На вход ей должен приходить тензор размерностью (1, 28, 28).__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ImprovedFashionMNISTModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(ImprovedFashionMNISTModel, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 64, kernel_size=3, padding=1)\n",
    "        self.bn1 = nn.BatchNorm2d(64)\n",
    "        self.conv2 = nn.Conv2d(64, 128, kernel_size=3, padding=1)\n",
    "        self.bn2 = nn.BatchNorm2d(128)\n",
    "        self.conv3 = nn.Conv2d(128, 256, kernel_size=3, padding=1)\n",
    "        self.bn3 = nn.BatchNorm2d(256)\n",
    "        self.pool = nn.MaxPool2d(2, 2)\n",
    "        self.fc1 = nn.Linear(256 * 3 * 3, 512)\n",
    "        self.fc2 = nn.Linear(512, 256)\n",
    "        self.fc3 = nn.Linear(256, 10)\n",
    "        self.dropout = nn.Dropout(0.5)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.pool(F.relu(self.bn1(self.conv1(x))))\n",
    "        x = self.pool(F.relu(self.bn2(self.conv2(x))))\n",
    "        x = self.pool(F.relu(self.bn3(self.conv3(x))))\n",
    "        x = x.view(-1, 256 * 3 * 3)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = self.dropout(x)\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.dropout(x)\n",
    "        x = self.fc3(x)\n",
    "        return x\n",
    "\n",
    "model_task_1 = ImprovedFashionMNISTModel()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "BcyEFX-RgSq8"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bAoLV4dkoy5M"
   },
   "source": [
    "Не забудьте перенести модель на выбранный `device`!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "id": "Xas9SIXDoxvZ"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ImprovedFashionMNISTModel(\n",
       "  (conv1): Conv2d(1, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (conv2): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (conv3): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  (fc1): Linear(in_features=2304, out_features=512, bias=True)\n",
       "  (fc2): Linear(in_features=512, out_features=256, bias=True)\n",
       "  (fc3): Linear(in_features=256, out_features=10, bias=True)\n",
       "  (dropout): Dropout(p=0.5, inplace=False)\n",
       ")"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_task_1.to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6pLRWysggSq9"
   },
   "source": [
    "Локальные тесты для проверки вашей модели доступны ниже:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "_qMQzo1ggSq9",
    "outputId": "c00008eb-ef88-4000-ce47-e8dedd26e061"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Everything seems fine!\n"
     ]
    }
   ],
   "source": [
    "# do not change the code in the block below\n",
    "# __________start of block__________\n",
    "assert model_task_1 is not None, \"Please, use `model_task_1` variable to store your model\"\n",
    "\n",
    "try:\n",
    "    x = random_batch[0].to(device)\n",
    "    y = random_batch[1].to(device)\n",
    "\n",
    "    # compute outputs given inputs, both are variables\n",
    "    y_predicted = model_task_1(x)\n",
    "except Exception as e:\n",
    "    print(\"Something is wrong with the model\")\n",
    "    raise e\n",
    "\n",
    "\n",
    "assert y_predicted.shape[-1] == 10, \"Model should predict 10 logits/probas\"\n",
    "\n",
    "print(\"Everything seems fine!\")\n",
    "# __________end of block__________"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "suRmIPwIgSq9"
   },
   "source": [
    "Настройте параметры модели на обучающей выборке. Также рекомендуем поработать с `learning rate`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "id": "YJnU14bdnZa_"
   },
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model_task_1.parameters(), lr=0.0005, weight_decay=1e-5)\n",
    "scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, 'max', patience=2, factor=0.5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20, Loss: 0.4664, Test Accuracy: 0.8803\n",
      "Epoch 2/20, Loss: 0.2917, Test Accuracy: 0.9044\n",
      "Epoch 3/20, Loss: 0.2449, Test Accuracy: 0.9108\n",
      "Epoch 4/20, Loss: 0.2109, Test Accuracy: 0.9105\n",
      "Epoch 5/20, Loss: 0.1860, Test Accuracy: 0.9234\n",
      "Epoch 6/20, Loss: 0.1662, Test Accuracy: 0.9205\n",
      "Epoch 7/20, Loss: 0.1474, Test Accuracy: 0.9222\n",
      "Epoch 8/20, Loss: 0.1311, Test Accuracy: 0.9189\n",
      "Epoch 9/20, Loss: 0.1158, Test Accuracy: 0.9246\n",
      "Epoch 10/20, Loss: 0.1062, Test Accuracy: 0.9231\n",
      "Epoch 11/20, Loss: 0.0958, Test Accuracy: 0.9242\n",
      "Epoch 12/20, Loss: 0.0848, Test Accuracy: 0.9270\n",
      "Epoch 13/20, Loss: 0.0780, Test Accuracy: 0.9255\n",
      "Epoch 14/20, Loss: 0.0726, Test Accuracy: 0.9232\n",
      "Epoch 15/20, Loss: 0.0668, Test Accuracy: 0.9291\n",
      "Epoch 16/20, Loss: 0.0616, Test Accuracy: 0.9243\n",
      "Epoch 17/20, Loss: 0.0596, Test Accuracy: 0.9228\n",
      "Epoch 18/20, Loss: 0.0535, Test Accuracy: 0.9250\n",
      "Epoch 19/20, Loss: 0.0523, Test Accuracy: 0.9263\n",
      "Epoch 20/20, Loss: 0.0483, Test Accuracy: 0.9218\n"
     ]
    }
   ],
   "source": [
    "num_epochs = 20\n",
    "train_losses = []\n",
    "test_accuracies = []\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    model_task_1.train()\n",
    "    running_loss = 0.0\n",
    "    for images, labels in train_data_loader:\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        outputs = model_task_1(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        running_loss += loss.item()\n",
    "    \n",
    "    model_task_1.eval()\n",
    "    test_acc = get_accuracy(model_task_1, test_data_loader)\n",
    "    test_accuracies.append(test_acc)\n",
    "    \n",
    "    train_loss = running_loss / len(train_data_loader)\n",
    "    train_losses.append(train_loss)\n",
    "    \n",
    "    print(f'Epoch {epoch+1}/{num_epochs}, Loss: {train_loss:.4f}, Test Accuracy: {test_acc:.4f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2zce7gt1gSq-"
   },
   "source": [
    "Также, напоминаем, что в любой момент можно обратиться к замечательной [документации](https://pytorch.org/docs/stable/index.html) и [обучающим примерам](https://pytorch.org/tutorials/).  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "usswrWYOgSq-"
   },
   "source": [
    "Оценим качество классификации:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "id": "Xua3TVZHgSq-"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Neural network accuracy on train set: 0.9869\n"
     ]
    }
   ],
   "source": [
    "train_acc_task_1 = get_accuracy(model_task_1, train_data_loader)\n",
    "print(f\"Neural network accuracy on train set: {train_acc_task_1:3.5}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "id": "l9KEKXBxgSq-"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Neural network accuracy on test set: 0.9218\n"
     ]
    }
   ],
   "source": [
    "test_acc_task_1 = get_accuracy(model_task_1, test_data_loader)\n",
    "print(f\"Neural network accuracy on test set: {test_acc_task_1:3.5}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4oyhmMobgSq_"
   },
   "source": [
    "Проверка, что необходимые пороги пройдены:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 181
    },
    "id": "OAIrURCEgSq_",
    "outputId": "7c983690-a92e-4693-89fb-7c86c002921a"
   },
   "outputs": [],
   "source": [
    "assert test_acc_task_1 >= 0.885, \"Train accuracy is below 0.885 threshold\"\n",
    "assert (\n",
    "    train_acc_task_1 >= 0.905\n",
    "), \"Train accuracy is below 0.905 while test accuracy is fine. We recommend to check your model and data flow\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Обращаем внимане, код ниже предполагает, что ваша модель имеет содержится в переменной `model_task_1`, а файл `hw_fmnist_data_dict.npy` находится в той же директории, что и ноутбук (он доступен в репозитории)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File saved to `submission_dict_fmnist_task_1.json`\n"
     ]
    }
   ],
   "source": [
    "# do not change the code in the block below\n",
    "# __________start of block__________\n",
    "assert os.path.exists(\n",
    "    \"hw_fmnist_data_dict.npy\"\n",
    "), \"Please, download `hw_fmnist_data_dict.npy` and place it in the working directory\"\n",
    "\n",
    "loaded_data_dict = np.load(\"hw_fmnist_data_dict.npy\", allow_pickle=True)\n",
    "\n",
    "submission_dict = {\n",
    "    \"train_predictions_task_1\": get_predictions(\n",
    "        model_task_1, torch.FloatTensor(loaded_data_dict.item()[\"train\"])\n",
    "    ),\n",
    "    \"test_predictions_task_1\": get_predictions(\n",
    "        model_task_1, torch.FloatTensor(loaded_data_dict.item()[\"test\"])\n",
    "    ),\n",
    "}\n",
    "\n",
    "with open(\"submission_dict_fmnist_task_1.json\", \"w\") as iofile:\n",
    "    json.dump(submission_dict, iofile)\n",
    "print(\"File saved to `submission_dict_fmnist_task_1.json`\")\n",
    "# __________end of block__________"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Сдача задания\n",
    "Сдайте сгенерированный файл в соответствующую задачу в соревновании, а именно:\n",
    "    \n",
    "* `submission_dict_fmnist_task_1.json` в задачу Separation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OtWnYAN_gSrA"
   },
   "source": [
    "На этом задание завершено. Поздравляем!"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
